---
layout: default
---

# 嵌入式AI简报 (2019-04-27)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  
<font>注：PC端微信链接打不开请用手机打开</font>


## 业界新闻

- [Xilinx 宣布收购 Solarflare | 赛灵思](https://mp.weixin.qq.com/s/R3eoY1BX1aw9QcA9LIgGgw)  
摘要：Solarflare 是一家全球领先的高性能、低时延网络解决方案提供商，其客户横跨金融科技到云计算。通过此次收购案，赛灵思能够将其业界领先的 FPGA、MPSoC 和 ACAP 解决方案与 Solarflare 的超低时延网络接口卡（NIC，网卡）技术以及 Onload 应用加速软件相结合，从而实现全新的融合 SmartNIC 解决方案，加速赛灵思的“数据中心优先”战略及向平台公司转型之路。  
- [苹果新 iPhone 大曝光：A13 芯片 AI 算力飙升，后置三摄设计 | 雷锋网](https://mp.weixin.qq.com/s/1NqHN5WHN4SPYHaIBp0IXA)  
摘要：与 A12 相比，A13 的 CPU 可能将继续采用 2 个大核 + 4 个小核的架构，或者采用 3 个大核，但苹果会通过架构微调来提升 CPU 频率。从单核和多核的情况来看，苹果 A 系列的单核 CPU 表现一直是稳步提升，但多核表现不太稳定，比较难以预测。  
GPU 方面，依据过去的增长规律，Jason Cross 认为 A13 在 GPU 方面的 3DMark Sling Shot 评分可能会在 4500 分左右。不过，在图像处理和 Neural Engine 方面，Jason Cross 认为苹果将会在 A13 上大幅度提升这一块的表现，来满足日益增加的 On-Device 机器学习和图像处理的需求——一个可参考的对象是，A12 比 A11 的 Neural Engine 运算速度提升了 8 倍，据此 Jason Cross 认为这一次的提升可能是 3 倍到 5 倍。
- [英特尔发布第九代酷睿移动处理器，为笔记本电脑而生 | 爱范儿](https://mp.weixin.qq.com/s/MgWhbk5WzFS37kH4owJ4Hg)  
摘要：英特尔于 4 月 25 日正式推出了面向笔记本电脑市场的第九代酷睿系列处理器，仍基于 14nm Coffe Lake 架构。其中未锁频版 Core i9-9980HK，采用 8 核心 16 线程，基础频率 2.4GHz，睿频达 5GHz，还支持 Thermal Velocity Boost 及 16MB 缓存。第九代酷睿移动版处理器将支持英特尔 Dynamic Tuning 技术，可动态调整性能与温度。  
- [Docker开发者现在可以在自己的桌面上构建Arm容器 | Docker](https://mp.weixin.qq.com/s/AOfUwCTD5X1su4VSTJIHGw)  
摘要：Docker与Arm公布一项重要的全新合作伙伴计划：两家公司将共同为Docker的工具提供面向Arm平台的更佳支持能力。此次合作的主要思路，是帮助Docker开发人员轻松立足自己的x86桌面设备为Arm平台构建应用程序，而后将应用成果部署至云端（包括基于Arm的AWS EC2 A1实例）、边缘以及物联网设备。具体来讲，开发者的Arm容器构建流程将与以往保持一致，无需任何交叉编译步骤。  
- [百度购买 Arteris IP 的FlexNoC®互联产品用于数据中心的昆仑人工智能（Kunlun AI）云芯片 | design-reuse](https://cn.design-reuse.com/news/45420/arteris-ip-flexnoc-interconnectbaidu-kunlun-ai-cloud-chip-data-center.html)  
摘要：今天宣布Baidu已购买Arteris IP FlexNoC互连，用于该公司的供数据中心使用的高性能昆仑人工智能云芯片。百度的昆仑人工智能云芯片是独一无二的产品，这是因为，无论它们是位于数据中心，还是位于车辆或消费电子等“周边”设备中，既能够进行人工智能训练，也能够进行推理。  
- [旷视研究院新出8000点人脸关键点，堪比电影级表情捕捉 | 知乎](https://zhuanlan.zhihu.com/p/62954487)  
摘要：旷视提出了“ 8000 点人脸关键点定位技术”——可通过 8000 个 3D 关键点实现全脸的精细定位，支持各种姿态表情，能在移动端实时运行。最终训练的Shufflenetv2模型运算量为 32 MFLOPS，在中端处理器骁龙660 上的平均运行时间为：10.5ms，而在高端处理器骁龙855 上的平均运行时间可达：4ms，帧速率 250fps。


## 论文

- [CNN更新换代OctConv！性能提升算力减半，还即插即用 | 知乎](https://zhuanlan.zhihu.com/p/62598364)    
摘要：Facebook和新加坡国立大学联手提出了新一代替代品：OctConv（Octave Convolution），效果惊艳，用起来还非常方便。OctConv就如同卷积神经网络（CNN）的“压缩器”。用它替代传统卷积，能在提升效果的同时，节约计算资源的消耗。比如说一个经典的图像识别算法，换掉其中的传统卷积，在ImageNet上的识别精度能获得1.2%的提升，同时，只需要82%的算力和91%的存储空间。  
- [吊打YOLOv3！普林斯顿大学提出：CornerNet-Lite，基于关键点的实时且精度高的目标检测算法，已开源！ | CVer](https://mp.weixin.qq.com/s/lk268kc55Lgz1d_21zg26A)  
摘要：截止2019年4月20日，据Amusi所了解，CornerNet-Lite 应该是目标检测（Object Detection）中 FPS和 mAP trade-off 最佳算法。
CornerNet-Saccade 是追求高准确率(mAP)的同时，尽可能提高速度(FPS)，即准确率优先，其对标于CornerNet等算法。创新点：引入Saccade思想CornerNet-Squeeze 是追求高实时性(FPS)的同时，尽可能提高准确率(mAP)，即速度优先，其对标于YOLOv3等算法。创新点：引入SqueezeNet优化思想。  
CornerNet-Saccade 检测图像中可能的目标位置周围的小区域内的目标。它使用缩小后的完整图像来预测注意力图和粗边界框；两者都提出可能的对象位置，然后，CornerNet-Saccade通过检查以高分辨率为中心的区域来检测目标。它还可以通过控制每个图像处理的最大目标位置数来提高效率。  
CornerNet-SqueezeNet 是受SqueezeNet启发，CornerNet-Squeeze将 residual block 替换为SqueezeNet中的 Fire module 。  
受MobileNet启发，CornerNet-Squeeze将第二层的3x3标准卷积替换为 3x3 深度可分离卷积（depth-wise separable convolution）。  
- [SysML] [Accurate and Efficient 2-Bit Quantized Neural Netowrks](https://www.sysml.cc/doc/2019/168.pdf) [[机器之心解读]](https://mp.weixin.qq.com/s/HzgRHtVwdmW6_m7OJwK-ew)  
摘要：为得到整体的量化神经网络（QNN），这篇论文提出分别用于权重和激活的量化技术：
    1. 激活量化的技术「PArameterized Clipping acTivation（PACT）」：在训练期间使用 ReLU 函数的参数化截略来确定量化的输出范围的方案；
    2. 用于权重量化的技术「Statistics-Aware Weight Binning（SAWB）」：可基于权重分布的统计特性确定能最小化量化误差的最优比例因子，无需执行穷举搜索。  
组合使用 PACT 与 SAWB 可以得到一种二位量化神经网络（2-bit QNN），其分类准确度在一些常见的模型和数据集上能达到当前最佳水平。
- [SysML] [Optimizing DNN Computation With Relaxed Graph Substitution](https://www.sysml.cc/doc/2019/22.pdf) [[机器之心解读]](https://mp.weixin.qq.com/s/HzgRHtVwdmW6_m7OJwK-ew)  
摘要：DNN 可被视为由（数学）算子组成的计算图。TensorFlow、PyTorch 和 TVM 等会将计算表达为有状态的数据流图，并在训练期间优化图，并会在整个过程中变换为新图。新图相比于迭代前的图通常会有严格更好的运行时间性能。这种「严格更好」会得到深度学习框架的非常受限的搜索空间，也是高计算成本的一大原因。直观地说，可以认为优化问题存在诸多约束。约束越多，算法得到解的时间就会越长。  
例如，如果 conv3 是一个 3×3 卷积，其核可分解为使用两个 1×3 核执行卷积（6 次乘法）但结果还是一样，从计算角度看，每次卷积的成本更低了。此外，通过将卷积分为两个可以并行执行的更小卷积，执行整个卷积的速度也可能会更快。  
这一思路两个方向都有效，而且这正是图替换思想背后的基本直觉。如果源图和目标图计算出的输出在外部边上是数学上等价的，则图替代就是有效的。最后说明一点，宽松化的思路可按如下方式展示。考虑以下等价表达式以及从上面的表达式到下面的表达式所采取的步骤：  
![graph-opt](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibRziaEw20HY7S6ToICwUH9Z8uJ6XOdWQdX6mtlIJPUO7XYRLG2nFgDDDSXGFxfrnEHaLL06ToupSw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)  
但是，如果系统每次迭代时都有约束——新子图必须严格优于当前子图；则第二个表达式就不会被允许，因此也就无法得到最终的表达式。这就体现了放松约束条件（宽松化）的重要性。   
因此为了解决这个问题从而降低计算成本，这篇论文提出了一种宽松化的图替代方法，可通过放松每个迭代约束的「严格更好」来实现复杂图优化的探索。这能增大问题的可行空间，并能在每次迭代时更快找到解。此外，研究者还引入了回溯方法（backtracking），可搜索一组宽松化图替代来寻找每次迭代的最优解（没有严格更好的约束）。   
- [英特尔“演化算法”新框架：29个Python代码块，自动生成新算法 | 新智元](https://mp.weixin.qq.com/s/q93z9cio7GwjXR36PgU16w) [[论文]](https://arxiv.org/abs/1904.02830)  
摘要：英特尔的研究人员提出一种新的自动算法生成器（AAD），利用演化算法框架，以Python语言的基本子集作为语法架构，能够对29个数组/向量问题的代码块进行组合，通过学习，自动生成更复杂问题的解决方案。  
自动算法发现器（AAD），这是一种用于合成高复杂度计算程序的演化算法框架。此前的演化算法依赖于客观的适应函数，这在给算法设计上增加了难度。  
AAD是用于综合高复杂度程序的演化框架，它以Python语言的基本子集作为语法架构。使用AAD能够对29个数组/向量问题的代码块进行组合，其中既有最大值、最小值，矩阵翻转这类简单问题，也有更具挑战性的问题，如排序和矩阵向量乘法等，对于输入没有大小限制。  
为了应对复杂需求带来的各种挑战，AAD工具还能实现与高性能计算（HPC）技术的结合。总的来说，与现有技术相比，采用PGE的演化算法能够解决类似或更高复杂性的问题。

## 开源项目

- [xperroni/Valdroid: Binary build of Valgrind for Android](https://github.com/xperroni/Valdroid)  
摘要：Android版本Valgrind。  
- [darchons/android-gdb: GDB fork targetting Android/Fennec development](https://github.com/darchons/android-gdb)
摘要：Android版gdb，用的时候adb push到手机上。注：不是gdbserver。
- [用Modin利用多核加速Pandas计算 | 机器之心解读](https://mp.weixin.qq.com/s/QDTMvvCUN71_L4nPgqzN1Q)  
摘要：Modin 是加州大学伯克利分校 RISELab 的一个早期项目，旨在促进分布式计算在数据科学领域的应用。它是一个多进程的数据帧（Dataframe）库，具有与 Pandas 相同的应用程序接口（API），使用户可以加速他们的 Pandas 工作流。  
例如，在一台 8 核的机器上，用户只需要修改一行代码，Modin 就能将 Pandas 查询任务加速 4 倍。Modin 所做的只是增加了 CPU 所有内核的利用率，从而提供了更好的性能。该系统是为希望程序运行得更快、伸缩性更好，而无需进行重大代码更改的 Pandas 用户设计的。这项工作的最终目标是能够在云环境中使用 Pandas。
    1. Modin 的架构数据帧分区，Modin对数据帧的分区模式是沿着列和行同时进行划分的，因为这样为 Modins 在支持的列数和行数上都提供了灵活性和可伸缩性。
    ![modin](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibr720w0uHY8x7z0xwEkmur3yr8gkUYtkI1lxheYuPHYjnGJu0X1xIqLA7m5ibS0ZjFqAtAxYXx4PA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)  
    2. Modin 系统架构被分为不同的层：
        1. Pandas API 在最顶层暴露给用户。
        2. 下一层为查询编译器，它接收来自 Pandas API 层的查询并执行某些优化。
        3. 最后一层为分区管理器（Partition Manager），负责数据布局并对发送到每个分区的任务进行重组、分区和序列化。
        ![modin-architecture](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibr720w0uHY8x7z0xwEkmur0pKNNnO7KWLuiajKdX8ia449zHybdibY797VTeibA4PV2o2pQpkHTibcl8A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
Modin 利用 [Ray](http://github.com/ray-project/ray) 加速 Pandas 的 notebook、脚本和程序库。Ray 是一个针对大规模机器学习和强化学习应用的高性能分布式执行框架。同样的代码可以在单台机器上运行以实现高效的多进程，也可以在集群上用于大型计算。
        
## 博文

- [ARM嵌入式开发中的GCC内联汇编简介 | Linux公社](https://www.linuxidc.com/Linux/2012-11/74645.htm)  
摘要：在针对ARM体系结构的编程中，一般很难直接使用C语言产生操作协处理器的相关代码，因此使用汇编语言来实现就成为了唯一的选择。但如果完全通过汇编代码实现，又会过于复杂、难以调试。因此，C语言内嵌汇编的方式倒是一个不错的选择。然而，使用内联汇编的一个主要问题是，内联汇编的语法格式与使用的编译器直接相关，也就是说，使用不同的C编译器内联汇编代码时，它们的写法是各不相同的。本文介绍在ARM体系结构下GCC的内联汇编。
- [关于CPU Cache -- 程序猿需要知道的那些事 | cenalulu's Tech Blog](http://cenalulu.github.io/linux/all-about-cpu-cache/)  
摘要：作者从为什么要有CPU Cache到多级CPU Cache、什么是Cache Line、存放数据规则、N-Way Set Associaive、Cache淘汰策略介绍了CPU Cache。
- [多角度解析Tesla FSD自动驾驶芯片 | StarryHeavensAbove](https://mp.weixin.qq.com/s/-e1rnh0qYj92jHncIYPoPA)  
摘要：在刚刚结束的Tesla Autonomy活动中，Tesla非常“大方”的介绍了自己的Full Self-Driving (FSD) Computer从系统到芯片的很多细节。从芯片来看，其“透明度”超过了除Google第一代TPU之外所有的AI相关芯片。实际上，和Goolge TPU的情况类似，在这次发布之前，Tesla也做了一定的专利布局，这正好让我们可以从不同角度更深入的了解Tesla的FSD芯片。  
- [华为“方舟编译器”到底是个什么鬼？ | 嵌入式资讯精选](https://mp.weixin.qq.com/s/keJ94tnvg_1evC2GTIc7Sw)  
摘要：方舟编译器作为全新的系统及应用的编译和运行机制，从DNA层面对安卓进行了改造，解决了安卓应用边解释边运行的低效问题，让手机能直接听懂“高级语言”，可以说是近几年来安卓阵营最大的根本性革新。它大幅降低了安卓系统随机卡顿的问题，打破了人机之间的藩篱，让用户能直观感受到的就是使用体验更加持久流畅。  
- [视频回放：诸宸辰-CVPR2019:基于Anchor-free特征选择模块的单阶目标检测 | 极市平台](https://mp.weixin.qq.com/s/8xXzOgqGU0XgRqY5s0NRrA)  
摘要：CMU博士生诸宸辰，为我们分享了其在CVPR2019的工作：基于Anchor-free特征选择模块的单阶目标检测。
- [豆瓣评分9.7！《树莓派开始，玩转Linux》 | 程序员书库](https://mp.weixin.qq.com/s/ZDkoZjtG4aIgT9i657kLIg)  
摘要：这本书，是以树莓派为基础，讲解Linux操作系统，让你不仅可以了解树莓派的背景知识，树莓派的使用，Linux使用，还能了解到操作系统的原理并且还有实操项目，你会不会有想看它的冲动呢？不卖关子了，这本书就是——《树莓派开始，玩转Linux》。章节目录除了基本Linux外，还有安装Spark计算pi的实例，搭建集群，跑YOLO模型等等案例。


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

![wechat_qrcode](../wechat_qrcode.jpg)

Wechat ID: NeuroMem  
Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
