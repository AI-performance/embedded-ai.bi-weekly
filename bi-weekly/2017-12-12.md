---
layout: default
---

# 嵌入式AI 双周简报 (2017-12-12)

## 业界新闻

- [马斯克首度承认自研AI芯片，或与英伟达“分手“ | 新智元](https://mp.weixin.qq.com/s?timestamp=1513062408&src=3&ver=1&signature=fTQ93DETY2RWqbThhgdlcBq1RqsL571fcPqXLNCeQ5RaGAnW4migmjYgbzZ0hKekbWTdE1idDJoFbARX5zUbSjC5dKYcQorRG6rvmpvr0tWawDwFudYkM*fi3DjMvl8sdbd7uEj2udk37OOZP3p0JGja29AypFVRTasFZ5F6ODk=) <br />
简评：特斯拉CEO Elon Musk在NIPS上公开承认，特斯拉正在开发专用的AI芯片。而同时，英伟达也在NIPS上发布了迄今为止最强大的“TITAN V” PC GPU。
- [全面对比英伟达Tesla V100/P100 Tensor Core的RNN加速能力 | 机器之心](https://mp.weixin.qq.com/s?timestamp=1513064452&src=3&ver=1&signature=fTQ93DETY2RWqbThhgdlcHCPhAS9hfeG3*KZPXWTck9Jbvjq*MoXpnIbzJ5b1w8x81SbAUlxwsFMnnf*RHj-o*sxTW9KUv508uyYMXZIUp2r6MCM3H3GZu-6tGUYDUljYOn2pPUrzWqRZJlN3-hWvqmEuRrkFXVh1VNLEwl83*o=) <br />
简评：RNN 是处理量化金融、风险管理等时序数据的主要深度学习模型，但这种模型用 GPU 加速的效果并不好。本文使用 RNN 与 LSTM 基于 TensorFlow 对比了英伟达 Tesla P100（Pascal）和 V100（Volta）GPU 的加速性能，且结果表明训练和推断过程的加速效果并没有我们预期的那么好。
- [Announcing Core ML support in TensorFlow Lite | Google Developers](https://developers.googleblog.com/2017/12/announcing-core-ml-support.html) <br />
简评：谷歌宣布Core ML支持加载TensorFlow模型。此外，谷歌将会继续致力于TensorFlow Lite的跨平台，包括iOS平台。
- [ONNX V1 released | Facebook Research](https://research.fb.com/onnx-v1-released/) <br />
简评：今年九月开源神经网络交换格式被开源，这是一种开源的模型格式。如今，Caffe2，CNTK，MXNet，Pytorch，TensorRT都已经支持该模型格式，且可用于生产环境。
- [IBM推出机器学习加速“瑞士军刀”Power9芯片，性能为同类产品的10倍 | 新智元](https://mp.weixin.qq.com/s?timestamp=1513062415&src=3&ver=1&signature=fTQ93DETY2RWqbThhgdlcBlBx4tfraHNaizVJ4n-G5h4vphOJrIfT*OtM6NhvEmL1oYVtn1LYgKMeIWKD9NX77SYNFLAofIAMOV-dPGWrDJ01xT3Hca7zaXnyEZbacX58hEB5UBkSYgyiVjBOvczEU1vPh8sY4CVUm2eQvPVskE=) [[原文](https://www.ibm.com/blogs/research/2017/12/10x-faster-using-gpu/)] [[paper](https://arxiv.org/abs/1708.05357)] <br />
简评：IBM最新一代的Power9正在进入市场，是目前唯一采用最先进的I / O子系统技术的处理器，包括下一代NVIDIA NVLink，PCIe Gen4和OpenCAPI。与x86比：最大9.5倍I / O带宽；2倍核心高性能；2.6倍RAM支持；1.8倍内存宽带。可以让Chainer，TensorFlow和Caffe等通用AI框运行的workloads增加近4倍。


## 开源项目

- [ucla-vision/parle](https://github.com//ucla-vision/parle) [[paper](https://arxiv.org/abs/1707.00424)] <br />
简评：Parle：用于深度学习并行训练的框架。该算法可以对同一个网络进行并行训练，可以把他们称为分片（replicas），通过并行SGD训练单个网络，收敛速度相比原本快2~4倍，同时还可达到更好的泛化性能。目前还只是CPU版本，即将提供多GPU版本的支持。
- [victordibia/handtracking: Building a Real-time Hand-Detector using Neural Networks (SSD) on Tensorflow](https://github.com//victordibia/handtracking) <br />
简评：作者基于TensorFlow框架实现的SSD模型的手检测器。作者在Macbook pro上进行了实验，在输入图像为320x240大小下，可以达到21FPS。
- [jwyang/faster-rcnn.pytorch](https://github.com//jwyang/faster-rcnn.pytorch) <br />
简评：更快的faster R-CNN实现。该项目用于加速faster R-CNN物体检测模型的训练，当然作者也承认参考了不少其他人的实现。
- [apple/turicreate: Turi Create simplifies the development of custom machine learning models.](https://github.com//apple/turicreate) <br />
简评：Turi是一个见到那构建机器学习模型的Python包，可以轻松训练自己的CoreML机器学习模型，去实现推荐、目标检测、图像分类甚至图像相似度检测或行为分类等等。


## 论文

- [1712.03112] [Effective Extensible Programming: Unleashing Julia on GPUs](https://arxiv.org/abs/1712.03112) <br />
简评：作者认为对计算密集型、可并行化的应用中编写并行化的低级语言程序较为困难，而使用GPU或其它加速计算设备是又很普遍的。为了解决这一问题作者提出可高效支持硬件的编译架构，用于对现有高级的Julia编程语言对GPU编程的支持。
- [1611.01576] [Quasi-Recurrent Neural Networks](https://arxiv.org/abs/1611.01576) [[code](https://github.com//JayParks/quasi-rnn)] [[blog](https://einstein.ai/research/new-neural-network-building-block-allows-faster-and-more-accurate-text-understanding)] <br />
简评：递归神经网络在序列建模上面有巨大优势，然而因为时序的计算依赖原因无法并行化导致训练效率很低。作者提出一种QRNNs（quasi-recurrent neural networks）方法，可以对序列建模的同时对时序过程并行化。此外，在相同隐藏层单元数目下，QRNNs比堆叠LSTMs有更好的预测精度，训练和测试时间也比原本快16倍，在语言建模、情感分类、字符级别的翻译任务上表现出了巨大优势。
- [1711.11460] [VoiceMask: Anonymize and Sanitize Voice Input on Mobile Devices](https://arxiv.org/abs/1711.11460) <br />
简评：语音输入通过云端的快速识别相比打字方便，但上传过程会造成隐私和敏感信息的泄露。作者在用户与云端间设立了一个用来保护隐私的名为VoiceMask的中间层，可以保护用户身份和隐私；同时还是用了关键词替换技术。这两个阶段都是在移动设备上进行。在50人的测试中，使用该技术语音识别准确率只下降了14.2%。
- [1712.02170] [Detecting Curve Text in the Wild: New Dataset and New Solution](https://arxiv.org/abs/1712.02170) [[code](https://github.com/Yuliang-Liu/Curve-Text-Detector)] <br />
简评：近年来自然场景的文字检测有很大进展，然而对曲线文本等场景效果不尽人意。作者因此构建了一个名为CTW1500的曲线文本数据集，包含1500张图像上超过1万的文本信息，其中训练样本1000个，测试样本500个。此外，作者提出基于多边形的曲线文本检测器，可以在无经验组合下直接检测曲线文本，以及两种后处理方法（非多边形抑制、多边形非最大抑制）来进一步提高检测性能。代码开源！


## 博文

- [专访Velodyne自动驾驶VP：无人驾驶量产得靠128线廉价激光雷达，中国将是最大市场 | 新智元](https://mp.weixin.qq.com/s?timestamp=1513062415&src=3&ver=1&signature=fTQ93DETY2RWqbThhgdlcBlBx4tfraHNaizVJ4n-G5h4vphOJrIfT*OtM6NhvEmL1oYVtn1LYgKMeIWKD9NX72BBait0OkwXLIUNLsq5Wx5JiXoMrkvOW1atct-sHpmprfsbOcbK1-f99z*AGa2KSIKSvAgCufC0u0ukOOjq3IU=) <br />
简评：Velodyne 激光雷达（64线）曾定价7万多美元，被认为是无人驾驶走向商用不得不解决的成本问题。近日，Velodyne 又发布了性能更佳的128线激光雷达，但是其自动驾驶负责人却表示，价格将会史无前例的低。此前，他们曾表示64线激光雷达可以从7万美元降到50美元。面对谷歌 Waymo自己打造价格只有其十分之一的激光雷达，特斯拉根本不使用激光雷达的情况，Velodyne 新产品会有怎样的定价？
- [BP表达式与硬件架构：相似性构建更高效的计算单元 | 机器之心](https://mp.weixin.qq.com/s?timestamp=1513064452&src=3&ver=1&signature=fTQ93DETY2RWqbThhgdlcHCPhAS9hfeG3*KZPXWTck9Jbvjq*MoXpnIbzJ5b1w8x81SbAUlxwsFMnnf*RHj-o0JQgtuHqHM5e0uwRhAARDuTRQ2*uQEkHAhEDc6J2-WRuPUoWK*EVrFnn8ZlIXl*Qwa-FMvr91vZvIdqaRvfiv8=) <br />
简评：反向传播是当前深度学习主要使用的参数更新方法，因此深度学习的硬件设计也需要拟合这种反向传播的计算结构。本文从反向传播的抽象表达开始简要地分析了 BP 算法和脉动阵列架构（systolic array architecture）之间的相似性，从而表明了脉动阵列架构适合执行 BP 和进行模型训练。
- [Mask R-CNN2Go! On-device realtime person keypoint estimation on Samsung Galaxy S8 accelerated by Caffe2 and Qualcomm Snapdragon Neural Processing Engine | facebook](https://weibo.com/tv/v/FyzglwpK0) <br />
简评：Mask R-CNNGo是一个专为移动端DNN优化、且基于Mask R-CNN的实现。点击链接，观看行人关键点检测的视频演示，该演示是基于Samsung Galaxy S8手机，框架和处理引擎分别是Caffe2和Qualcomm Snapdragon Neural Processing Engine。
- [End to End Optimization Stack for Deep Learning by Tianqi Chen | learningsys](http://learningsys.org/nips17/assets/slides/TVM-MLSys-NIPS17.pdf) <br />
简评：深度学习端到端优化栈：TVM。
- [Computer System Colloquium: Petascale Deep Learning on a Single Chip by Tapabrata Ghosh | Standford](https://www.bilibili.com/video/av17077920/) <br />
简评：计算机系统研讨会关于单芯片千兆级深度学习（by Tapabrata Ghosh, Vathys）主题的视频录像。
- [Benchmarking Modern GPUs for Maximum Cloud Cost Efficiency in Deep Learning | minimaxir](http://minimaxir.com/2017/11/benchmark-gpus/) <br />
简评：云端GPU深度学习最新性能评测。
- [NVIDIA Deep Learning Inference Platform Performance Study | NVIDIA Developer News Center](https://news.developer.nvidia.com/nvidia-deep-learning-inference-platform-performance-study/) [[pdf](https://images.nvidia.com/content/pdf/inference-technical-overview.pdf)] <br />
简评：NVIDIA在深度学习推理方面的性能研究，具体内容请点击pdf查看该技术报告。

