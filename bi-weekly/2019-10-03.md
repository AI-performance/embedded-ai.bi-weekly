---
layout: default
---

# 嵌入式AI简报 (2019-10-03)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  
<font>注：PC端微信链接打不开请用手机打开</font>


## 业界新闻  

- [华为Mate 40曝光 首发麒麟1000处理器 | 安兔兔](https://mp.weixin.qq.com/s?__biz=MzA5NDI1MjA0Ng==&mid=2652087781&idx=2&sn=f4b17ee056b8f91c383e74e4fbd29984)  
摘要：报道称华为Mate 40将率先搭载麒麟1000芯片，该芯片基于台积电5nm工艺制程打造，考虑到7nm FinFET Plus EUV 麒麟990 5G集成了高达103亿个晶体管，如果麒麟1000使用5nm工艺制程，那么每平方毫米可能有多达1.713亿个晶体管。  
此外，报道还称麒麟1000可能会采用Cortex A77架构，性能表现值得期待。  
- [骁龙865来了！样片已开测 | 安兔兔](https://mp.weixin.qq.com/s?__biz=MzA5NDI1MjA0Ng==&mid=2652087748&idx=5&sn=d8ce0eec9066e80e701aebe28f3e01a3)  
摘要：近日有外媒报道称，索尼正在开发下一代Xperia旗舰，他们在索尼移动的固件分发服务器上找到了Xperia “SM8250”字样，而SM8250正是传闻中骁龙865的内部型号。  
有消息称，865提供两个版本，分别集成5G调制解调器和未集成5G调制解调器，厂商可以选择不同版本推出不同机型。  
- [阿里巴巴重磅发布含光800芯片：顶10个GPU | InfoQ](https://www.infoq.cn/article/i78THUqMJsY10ZavsFv4)  
摘要：去年云栖大会上，平头哥芯片公司横空出世，阿里也是从去年开始研发自己的 NPU 芯片。今年云栖大会上，NPU 有了重大突破：全球最高性能 AI 推理芯片含光 800 正式发布！在业界标准的 ResNet-50 测试中，含光 800 推理性能达到 78563 IPS，比目前业界最好的 AI 芯片性能高 4 倍；能效比 500 IPS/W，是第二名的 3.3 倍。  
- [比特大陆第三代云端AI芯片 | 雷锋网](https://mp.weixin.qq.com/s?__biz=MTM2ODM0ODYyMQ==&mid=2651457874&idx=4&sn=670019ccbfcc2f64c2b9fa249e4b50fb)  
摘要：比特大陆的第三代AI芯片BM1684，内置张量计算模块TPU，该TPU模块包含64个NPU运算单元，每个NPU包括16个EU单元，总共有1024个EU运算单元。BM1684为视频处理做了特别优化，单芯片最高支持32路H264/H265的解码能力，每秒480帧JPEG/PNG图片编解码，960 fps@1080p视频解码能力，更内置了视频图像前后处理硬件加速模块。    
第三代芯片的优势在于高性能和低功耗。同时，BM1684与国内最优秀和国外最优秀的厂商的对比。分别是在Restnet50、MobileNet、Vggnet16下处理能力和能效比的对比中可以看到，比特大陆最新款的AI云端芯片对比两个优秀芯片厂商都有不同程度的优势。  
基于台积电12nm工艺，在16w功耗下，BM1684 FP32精度算力达到2.2 TFlops，INT8算力可高达17.6Tops，在Winograd卷积加速下，INT8算力可提升至35.2Tops。
- [腾讯开源物联网操作系统 TencentOS tiny，最小体积 1.8KB！ | CSDN](https://mp.weixin.qq.com/s/JmvTRD5DyVFTn1hQHeselQ)  
摘要：TencentOS tiny的开源，难免让人联想到鸿蒙OS和方舟编译器的开源。目前，TencentOS tiny已支持意法半导体、恩智浦、华大半导体、瑞兴恒方、国民技术等主流厂商多种芯片和模组。支持复杂的任务管理、实时调度、时间管理、中断管理、内存管理、异常处理。  
对于开源，腾讯物联网团队表示：“将腾讯自主研发的物联网操作系统TencentOS tiny开源，不仅可以将腾讯在物联网领域的技术和经验，和全球开发者分享，还能够汲取全球物联网领域的优秀成果、和创新理念，最终推动整体物联网生态的繁荣、以及万物智联时代的到来。”

## 论文

- [1909.10788] [IR-Net: Forward and Backward Information Retention for Highly Accurate Binary Neural Networks](https://arxiv.org/abs/1909.10788)  
摘要：商汤在1-bit cnn上做的一些新工作，基于开源二值网络推理框架[JDAI-CV/dabnn: dabnn is an accelerated binary neural networks inference framework for mobile platform](https://github.com/JDAI-CV/dabnn)。  
- [TinyBERT：模型小7倍，速度快8倍，华中科大、华为出品 | 机器之心](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650771134&idx=2&sn=012082a897dbf125000e38b73520c51d)  
摘要：BERT 等大模型性能强大，但很难部署到算力、内存有限的设备中。为此，来自华中科技大学、华为诺亚方舟实验室的研究者提出了 TinyBERT，这是一种为基于 transformer 的模型专门设计的知识蒸馏方法，模型大小还不到 BERT 的 1/7，但速度是 BERT 的 9 倍还要多，而且性能没有出现明显下降。目前，该论文已经提交机器学习顶会 ICLR 2020。  
论文：https://arxiv.org/abs/1909.10351  
- [ICCV 2019：华为、北大等首创GAN剪枝算法，线上加速 3 倍以上 | 新智元](https://mp.weixin.qq.com/s/3_famaAmkAN-4xVEupSXSA)  
摘要：华为诺亚方舟实验室最新研究首次提出针对GAN中生成网络的剪枝算法，在图像迁移任务中，可以在保持迁移效果的情况下，网络参数量和计算量压缩四倍以上，实测推理时间压缩三倍以上。论文已被ICCV 2019录用。  

## 开源项目

- [LFFD 再升级！新增行人和人头检测模型，还有了优化的C++实现 | 我爱计算机视觉](https://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&mid=2247488646&idx=1&sn=e1849eda9652121c4255c9d40830240b)  
摘要：LFFD：中科院开源轻量级通用人脸检测器，其不仅仅可用于人脸检测，实际上是一款优秀的单类目标检测器。其最大特点是在精度接近SOTA的同时，速度非常快。  
最近该项目新增不少吸引人的特性，而且还有朋友再进一步优化LFFD，使其更适于工程开发。网友 @SyGoing使用C++语言实现和 NCNN、 MNN 、OpenViNO的LFFD。使其更有利于设备部署：  
  - NCNN版：https://github.com/SyGoing/LFFD-with-ncnn  
  - MNN版：https://github.com/SyGoing/LFFD-MNN  
  - OpenVINO版：https://github.com/SyGoing/LFFD-OpenVINO  
- [业界首个实时多目标跟踪系统开源 | 我爱计算机视觉](https://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&mid=2247488713&idx=1&sn=17e559b030ccfad34d0c9dc3cec6f8be)  
摘要：一篇多目标跟踪的论文Towards Real-Time Multi-Object Tracking，引起了不少人的关注，速度更快、精度更高、代码也已经开源了，非常值得参考。作者称，该算法是第一个实时的多目标跟踪算法。  
来自清华大学和澳大利亚国立大学。多目标跟踪往往采用tracking-by-detection 流程，分为用于目标定位的检测模型和目标关联的表观嵌入模型，长久以来，这两大模块是分开的。
该文提出的算法，MOTA接近state-of-the-art，比DeepSort精度高，速度快3-4倍。以上算法评估作者是在Nvidia Titan xp GPU上运行的。  
  - 论文地址：https://arxiv.org/pdf/1909.12605v1.pdf  
  - 开源代码：https://github.com/Zhongdao/Towards-Realtime-MOT  
- [嵌入式Linux GUI框架AWTK | ZLG立功科技一致远电子](https://mp.weixin.qq.com/s/6JGRrIiC2rQU_WuF7YVjGg)  
摘要：随着便携式智能设备的普及，用户对人机交互界面（GUI）的要求越来越高，而Qt的资源占用大等短板致使在某些应用仍存在难点。  
ZLG致远电子研发的AWTK是一套基于C语言的跨平台GUI开发框架，可用于开发物联网、消费电子、工业控制、汽车电子、智能家居等领域的应用产品，旨在为用户提供一个功能强大、高效可靠、简单易用、可轻松做出炫酷效果的GUI开发解决方案，使用户开发GUI应用就像开发串口应用一样简单。  
- [plasma-umass/coz: Coz: Causal Profiling](https://github.com/plasma-umass/coz)  
摘要：Coz is a new kind of profiler that unlocks optimization opportunities missed by traditional profilers. Coz employs a novel technique we call causal profiling that measures optimization potential. This measurement matches developers' assumptions about profilers: that optimizing highly-ranked code will have the greatest impact on performance. Causal profiling measures optimization potential for serial, parallel, and asynchronous programs without instrumentation of special handling for library calls and concurrency primitives. Instead, a causal profiler uses performance experiments to predict the effect of optimizations. This allows the profiler to establish causality: "optimizing function X will have effect Y," exactly the measurement developers had assumed they were getting all along.  
Full details of Coz are available in our paper, Coz: Finding Code that Counts with Causal Profiling (pdf), SOSP 2015, October 2015 (recipient of a Best Paper Award).
- [LieluoboAi/radish: C++ model train&inference framework](https://github.com/LieluoboAi/radish)  
摘要：Radish可以让你的模型从训练到部署都使用相同C++代码库， 借助libtorch, 让你专注实现模型及对应数据处理。  


## 博文

- [Paddle Lite特性全解读，多硬件支持、轻量化部署等亮点频现 | 飞桨PaddlePaddle](https://mp.weixin.qq.com/s?__biz=Mzg2OTEzODA5MA==&mid=2247488503&idx=1&sn=0911e8e2772e923566ed39f7861da4b3)  
摘要：本文主要由 9 月 21 日在百度科技园举办的 AI 快车道 Paddle Lite 专场的演讲材料整理而成，分别介绍了 Paddle Lite 的性能特性、使用方法、架构设计等，并且提供了完整的使用案例，可供开发者迅速开展应用。  
- Polyhedral Model—AI芯片软硬件优化利器 | 要术甲杰 StarryHeavensAbove    
摘要：神经网络中的很多重要算子都可以表现为嵌套的多重循环的形式，而以加速神经网络为目的的AI芯片和编译器，很多软硬件优化工作是对这些循环的变换和优化。Polyhedral Model是循环优化的“神器”，可以在AI芯片的软硬件优化中发挥巨大作用。笔者是研究和实践Polyhedral Model的专家，很高兴能邀请他给大家介绍一些这方面的知识。    
  1. [Polyhedral Model—AI芯片软硬件优化利器（一）](https://mp.weixin.qq.com/s/QEooKxP1sm5O90AUiqKQEQ)    
  2. [Polyhedral Model—AI芯片软硬件优化利器（二）](https://mp.weixin.qq.com/s/NRtud1UImE5ArZ2zQWFRyg)    
  3. [Polyhedral Model—AI芯片软硬件优化利器（三）](https://mp.weixin.qq.com/s/bLBIrJb82IsnyoXSEr2xtw)    
- [如何看待阿里平头哥发布的全球最高性能 AI 芯片「含光 800」？这款芯片核心技术是什么呢 | zhihu](https://www.zhihu.com/question/347692093)  
- [Blade Benchmark Suite(BBS)简介_PAI Blade推理优化框架 | 机器学习PAI-阿里云](https://help.aliyun.com/document_detail/140558.html)  
摘要：PAI-Blade是阿里巴巴自研的通用推理优化框架，通过模型系统联合优化达到最优的推理性能，即将在公共云与大家见面。  
为能够让您更好地了解和使用Blade优化工具，我们特别提供一个可试用、易验证的环境和若干模型，构成Blade Benchmark Suite，简称BBS。Blade BBS中共有8个不同类型的深度学习模型，涵盖图像分类、文字检测、自然语言处理等任务场景，Tensorflow、Caffe、Onnx等深度学习框架。在我们提供的docker环境中，可以通过一键式运行脚本run.sh依次进行Blade优化和若干基线测试，使用方法详见BBS使用说明。  
具体地，我们分别对比了Tensorflow、Tensorflow xla、TensorRT、Caffe、Caffe2等不同框架的性能表现，展示了FP32、FP16、INT8等不同精度的优化情况，对应的参考性能数据和详细说明可参见BBS性能数据。  
- [下一代HTTPS：蚂蚁金服推出新型可信中间件SOFAEnclave | InfoQ](https://www.infoq.cn/article/QxaxY7YXhWSDKcPzJ7a1)  
摘要：AI 模型安全保护。对外部署的 AI 模型携带大量知识产权，一旦被逆向或泄露，既会对技术护城河造成破坏，也会降低对抗性样本攻击的难度，导致安全问题。应对这种威胁的一种方案是，使用方把 AI 模型和训练 / 预测数据加密存储，只有在使用时才将其输入 Enclave，在 Enclave 里面解密，由 Enclave 中运行的 AI 框架处理，结果根据具体场景需求以明文返回或加密返回并在使用方本地解密。这要求 Enclave 能支持常见的 AI 框架，而要做到这一点极为挑战——一方面是因为这些 AI 框架一般使用了复杂的多线程、OpenMP 等性能优化的运行环境，另一方面是因为 Enclave 又偏偏难以提供这些支撑环境。这就是为什么市面上很多 Enclave 支撑系统难以支持（或难以高效支持）AI 框架的原因。  
Occlum LibOS 在这方面取得了一定的进展，可以较为轻松的高效运行常见 AI 框架。  
- [CS217课程解析：剖析QNNPACK的矩阵运算优化思路 | MikesICroom  MikesICroom](https://mp.weixin.qq.com/s/Fvh0tXeFOdn3Uyba5zrCXg)  
摘要：QNNPACK是facebook在2018年底推出的面向mobile AI的高性能开源加速库，可以在手机端提供2倍以上的性能提升。QNNPACK不但对传统的卷积有较好的加速，对于新兴的group convolution、depthwise convolution也有不错的效果。尽管这是纯软件的工作，其中很多优化方式和思想很值得借鉴。  
- [设计模型参数量小于1M的行人检测网络 | zhihu](https://zhuanlan.zhihu.com/p/76491446)  
摘要：原始的RFBNet300参数量有36.5 MB，我采用重新设计，削减了channel数目以及卷积数目以及使用1x1卷积，然后对网络进行了从头训练。在模型参数量只有0.99MB时，AP也能达到78。在模型参数量为3.1MB时，AP能达到80，并且速度还可以达到200FPS。  
- [CPU并行编程概述（上）| InfoQ](https://www.infoq.cn/article/uMp5KqDG1vWEYbcwES0Q)  


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


- [2019-09-16](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-09-16.md)
- [2019-08-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-30.md)
- [2019-08-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-08-15.md)
- [2019-07-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-30.md)
- [2019-07-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-07-15.md)
- [2019-06-29](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-29.md)
- [2019-06-17](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-06-17.md)
- [2019-05-30](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-30.md)  
- [2019-05-15](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-05-15.md)  
- [2019-04-27](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-27.md)  
- [2019-04-13](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-04-13.md)  
- [2019-03-31](https://github.com/ysh329/awesome-embedded-ai/blob/master/embedded-ai-report/2019-03-31.md)  

----

![wechat_qrcode](../wechat_qrcode.jpg)

Wechat ID: NeuroMem  
Editor: https://github.com/ysh329  
Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
