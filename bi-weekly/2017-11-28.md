---
layout: default
---

# 嵌入式AI 双周简报 (2017-11-28)

## 业界新闻

- [波士顿动力最新逆天机器人：360°后空翻完爆体操运动员，54秒看双足机器人未来 | 新智元](https://mp.weixin.qq.com/s?timestamp=1511612877&src=3&ver=1&signature=ohWeTUu0PRzwCTARieFAVLi*0Db4eahy4KJb4speOviiMO8Fmfxppr*oV5pow1kSypqsrhxU8uKYQKVj1OlPpzBRGrKnNxu-C8XXbCNEOJiZE*9KSBSnGpMtK4uiTrIoy-Psciyge4b2RGpw6OjwglEo0NNNEzRGUx1EHXrAk4g=) <br>
简评：波士顿动力公司在YouTube发布了一段新视频，展示了该公司的Atlas机器人做360度后空翻的惊艳动作。波士顿动力原是Alphabet旗下的机器人公司，今年6月被软银集团收购。
- [黄教主再放核弹，英伟达超级计算机SaturnV升级，有望杀入Top500榜单前五 | 新智元](https://mp.weixin.qq.com/s?timestamp=1511612877&src=3&ver=1&signature=ohWeTUu0PRzwCTARieFAVLi*0Db4eahy4KJb4speOviiMO8Fmfxppr*oV5pow1kSypqsrhxU8uKYQKVj1OlPp6oiM4jKWKICuZkoOCF2zz2YnL9IZlaZG0lJnoylFeYUaXO5RwPaOYRYqDK4fvjLVXBwqAB4W5MMqtkr5HbxTbU=) <br>
简评：最新一期国际超算权威榜单Top500发布，英伟达的DGX SaturnV 排名第36。就在昨天，英伟达宣布，使用最新的Volta升级该集群，一个DGX SaturnV里组装了660个DGX-1节点（每个节点8个V100芯片）。如果你把GPU从SaturnV中拿出来一个一个挨着放，差不多能排上一公里。
- [旷视&清华大学提出新型两步检测器Light-Head R-CNN | 机器之心](https://mp.weixin.qq.com/s?timestamp=1511612693&src=3&ver=1&signature=ohWeTUu0PRzwCTARieFAVJ-y5*BpkaIZyq6N*5CCDZm7C897Nu3JnfXd4Tbkq7xD0ioHkSpkchOHtrf5jSxk0c1i78bHVIDiX--RXSai33rCh3sD6doz7g*TZBi9xkyh6sF7oh7WOL8QwYh5Ygh5eZDGVNjHS-q0CRm-z9JGTHA=) <br>
简评：这篇论文提出一种轻量级检测器头设计以构建一个高效、准确率高的两步检测器。具体来说，使用一个大内核可分卷积和少量通道生成稀疏的特征图。该设计的计算量使随后的 RoI 子网络计算量大幅降低，检测系统所需内存减少。将一个廉价的全连接层附加到池化层上，可充分利用分类和回归的特征表示。算法灵活，适用于大型主干网络。基于 ResNet-101 的主干网络优于顶尖的算法，包括两步检测器如 Mask R-CNN 和一步检测器如 RetinaNet。
- [华为推出新型HiSR：移动端的超分辨率算法 | 机器之心](https://mp.weixin.qq.com/s?timestamp=1511612693&src=3&ver=1&signature=ohWeTUu0PRzwCTARieFAVJ-y5*BpkaIZyq6N*5CCDZm7C897Nu3JnfXd4Tbkq7xD0ioHkSpkchOHtrf5jSxk0c1i78bHVIDiX--RXSai33pw5ci8bOUE5C*ZF7tH1sJEZFmKQ3EGXq12OJ6XmgYPseqwxXWya*CTTdOdi4Qmo1E=) <br>
简评：近日，华为推出了 HiSR 超分辨率技术，该模型借助第一款人工智能手机芯片 Kirin 970 和深度学习算法将低分辨率图片转化生成高清图片，并在移动端实现了快速预览高清图片的效果。本文简要介绍了华为 HiSR 模型的结构与效果。

## 论文

- [1711.04528] [Simple And Efficient Architecture Search for Convolutional Neural Networks](https://arxiv.org/abs/1711.04528)<br />
简评：神经网络的架构选择通常由专家设计试错而得。作者提出一个基于爬山过程的网络形态的搜索方案，紧接一个余弦退火优化过程。用该方法在CIFAR-10数据集上训练出的模型错误率低于6%。
- [1711.03712] [Quantized Memory-Augmented Neural Networks](https://arxiv.org/abs/1711.03712)<br />
简评：增强记忆网络（Memory-augmented neural networks，MANNs）是指一类需要借助外部存储的网络模型，这种模型因有更长依赖的学习，因而比传统的RNN模型表现更好。然而，在嵌入式端部署这样的模型却是一个难题，作者提出QMANNs，即对MANNs进行8bit定点和二值量化。相比float实现和传统实现，8bit定点和二值量化在错误率46%和30%提升的前提下，可以达到22倍单位能耗计算量的提升。
- [1711.03637] [Learning and Real-time Classification of Hand-written Digits With Spiking Neural Networks](https://arxiv.org/abs/1711.03637)<br />
简评：作者提在通用GPU平台实现了一种新颖的SNN（spiking neural network）网络去实时地完成手写数字图片的分类任务。在MNIST数据集上达到了99.8%的训练集准确率和98.6%的测试集准确率，然而参数量只为性能最好的spking网络的七分之一。
- [1711.05491] [Squeeze-SegNet: A new fast Deep Convolutional Neural Network for Semantic Segmentation](https://arxiv.org/abs/1711.05491)<br />
简评：作者提出Squeeze-SegNet，这是一种可部署在嵌入式平台如自动驾驶场景下、用于语义分割的全卷积网络，其结构与编解码器非常类似，集合了squeeze-decoder模块、上采样以及反卷积层等等。在Camvid和City-states等数据集上达到了和SegNet一样的准确率，但参数量仅为SegNet的十分之一。
- [1708.05237] [S$^3$FD: Single Shot Scale-invariant Face Detector](https://arxiv.org/abs/1708.05237) [[code]](https://github.com//clcarwin/SFD_pytorch)<br />
简评：作者提出一种名为S^3FD（Single Shot Scale-invariant Face Detector）的实时人脸检测器，这是一个能胜任各种尺度输入的单神经网络模型，尤其是小人脸。而作者工作的重点就是要解决基于anchor的检测器在物体变小时，性能会下降的问题。作者主要做了以下三点：1.提出随尺度变化的人脸检测框架来解决人脸尺度的问题；2.通过尺度补充的anchor策略来提升对小人脸的召回；3.通过max-out背景标注来减少小人脸的false positive rate。在AFW、PASCAL face、FDDB和WIDER FACE这几个数据集上都达到了state-of-the-art的检测性能，在NVIDIA Titan X（Pascal）显卡上达到了36fps的帧率。
- [1711.05860] [A General Neural Network Hardware Architecture on FPGA](https://arxiv.org/abs/1711.05860) <br />
简评：现场可编程门阵列（FPGA）由于高度并行体系结构，低功耗，自定义算法的灵活性。在神经网络和机器学习算法的高能效实现上有巨大优势。作者基于XILINX ZU9CG系统芯片(SOC)平台，实现了一个支持训练和推断的通用神经网络硬件架构。
- [1711.05979] [Performance Modeling and Evaluation of Distributed Deep Learning Frameworks on GPUs](https://arxiv.org/abs/1711.05979) [译文](https://mp.weixin.qq.com/s?timestamp=1511612877&src=3&ver=1&signature=ohWeTUu0PRzwCTARieFAVLi*0Db4eahy4KJb4speOviiMO8Fmfxppr*oV5pow1kSypqsrhxU8uKYQKVj1OlPp77VYVevE7w9dImXgAAcyx*kuXDXzof7k4noulFDH2w9MdhMmWrK4F8n*ll0LnduT*x-ubwWH589hgHYw8RduY4=) <br>
简评：这篇论文评估了四个state-of-the-art的分布式深度学习框架，即Caffe-MPI, CNTK, MXNet 和 TensorFlow分别在单个GPU、多GPU和多节点的环境中的表现。
- [1711.07607] [Knowledge Concentration: Learning 100K Object Classifiers in a Single CNN](https://arxiv.org/abs/1711.07607)<br />
简评：超细粒度图像分类是图像搜索和移动AI助手所需要的。然而训练一个具有10万类的大型模型的训练速度和分类性能是一个挑战。一个解决方案是训练独立的专家网络，每个专家集中学习一个特定垂直领域（如汽车、鸟类等）。然而，在实际的系统中部署数大量专家网络会增大系统复杂性和推理延迟，并消耗大量的计算资源。作者提出一个知识浓度方法，将知识从数十名专家网络蒸馏成一个单一模型（一个学生网络）对100k类别分类。作者主要工作有三点：1.提出multi-teacher蒸馏的框架；2.自主学习机制，允许学生从不同的老师处学习；3.用结构连接层扩大学生网络容量。在OpenImage数据集上达到比baseline更大的性能提升。
- [1711.05908] [NISP: Pruning Networks using Neuron Importance Score Propagation](https://arxiv.org/abs/1711.05908)<br />
简评：作者提出基于神经传播重要性的剪枝策略（NISP，Neuron Importance Score Propagation
）。在往常的剪枝策略中没有考虑反向传播在重建误差时候的影响。作者将最小化重建误差纳入考量并设计出名为FRL（final response layer）的层，该层在softmax层之前用于巩固预测结果。此外，作者也对特征进行排序来测量每个神经元在FRL层中的重要性，将剪枝问题视为优化问题。整体实现流程是：先对网络基于最小重要性进行剪枝移除一些神经元，之后对网络fine-tune。在忽略不计的准确率损失下，几个数据集上都有很大的加速表现。
- [深度梯度压缩：降低分布式训练的通信带宽 | 机器之心](https://mp.weixin.qq.com/s?timestamp=1511612669&src=3&ver=1&signature=ohWeTUu0PRzwCTARieFAVJs6Jpbmv*C*X17REkTuIrEjfs0FAxzg32Zx0o*MNW6xJ40S-zlPmszHeNQbwQuZaW2KiCORMFnhNYuOwZR2dnfgejmkKAQXbD9NX01CYt38o9oIJ1RfqPb4G4EbTS7D5mO-fEAue7UwIybl0*RKOIs=) <br>
简评：深度梯度压缩（Deep Gradient Compression/DGC）是通过压缩梯度的方式来解决通信带宽问题。为了确保无损于准确度，DGC 在梯度稀疏化（gradient sparsification）之上使用了动量校正（momentum correction）和局部梯度裁剪（local gradient clipping）来维持模型的表现水平。DGC 还使用了动量因子掩蔽（momentum factor masking）和 warmup training 来克服由通信减少所导致的过时问题（staleness problem）。图像识别、语言建模和语音识别的实验表明：该方法可以将梯度压缩 600 倍而不造成准确度损失，这比之前的研究成果（Aji & Heafield, 2017）高一个数量级。 


## 开源项目

- [JianyangZhang/Self-Driving-Car-AI: A simple self-driving car AI python script using the deep Q-learning algorithm](https://github.com//JianyangZhang/Self-Driving-Car-AI)<br />
简评：Deep Q-learning无人车AI项目。
- [BlinkDL/BlinkDL: A minimalist deep learning library in Javascript using WebGL + asm.js. It can do convolutional neural network in your browser.](https://github.com/BlinkDL/BlinkDL)<br />
简评：一个极简Javascript中使用WebGL + asm.js深度学习库，它可以在浏览器中执行卷积神经网络。
- [masahi/nnvm-vision-demo: Demos interesting image-in, image-out networks running on both NVIDIA and AMD GPUs, with NNVM](https://github.com/masahi/nnvm-vision-demo)<br />
简评：用GAN实现图像生成，底层支持NVIDIA和AMD的GPU。
- [explosion/lightnet: 🌓 Bringing pjreddie's DarkNet out of the shadows #yolo](https://github.com//explosion/lightnet)<br />
简评：LightNet提供DarkNet简单高效的Python接口，DarkNet框架由YOLO和YOLOv2的作者实现。LightNet在的主要目的是做图像的目标检测和分割。
- [LamHoCN/Depth_conv-for-mobileNet: Depth_conv for MobileNet](https://github.com/LamHoCN/Depth_conv-for-mobileNet)<br />
简评：用CUDA实现的MobileNet的depth_conv。
- [hahnyuan/video_labeler: A GUI tool for conveniently label the objects in video, using the powerful object tracking.](https://github.com/hahnyuan/video_labeler)<br />
简评：视频标记工具，带有给力的跟踪辅助功能。
- [jcupitt/libvips: A fast image processing library with low memory needs.](https://github.com/jcupitt/libvips)<br />
简评：超快的图像处理框架。
- [AITTSMD/MTCNN-Tensorflow: Reproduce MTCNN using Tensorflow](https://github.com//AITTSMD/MTCNN-Tensorflow)<br />
简评：使用Tensorflow实现MTCNN。
- [Carla – An open-source simulator for autonomous driving research | Hacker News](https://news.ycombinator.com/item?id=15720314)<br />
简评：自驾模拟开发环境资源汇总。


## 博文

- [变形卷积核、可分离卷积？卷积神经网络中十大拍案叫绝的操作 | 知乎](https://zhuanlan.zhihu.com/p/28749411)<br />
简评：CNN从2012年的AlexNet发展至今，科学家们发明出各种各样的CNN模型，一个比一个深，一个比一个准确，一个比一个轻量。博文作者对近几年一些具有变革性的工作进行简单盘点，从这些充满革新性的工作中探讨日后的CNN变革方向。
- [苹果博客解读iPhone上的人脸识别深度神经网络 | 机器之心](https://mp.weixin.qq.com/s/hbmLhS114cEC5qGv2Ujxaw) [[英文原文]](https://machinelearning.apple.com/2017/11/16/face-detection.html)<br />
简评：苹果首次将深度学习应用于人脸识别是在 iOS 10 上。通过 Vision 框架，开发者现在可以在 App 中将该技术与其他很多计算机视觉算法进行整合。为了保护用户隐私，保证有效运行，苹果在开发这个框架的过程中克服了大量挑战。本文旨在探讨这些挑战，并介绍人脸识别算法。
- [从人脸识别到行人重识别，下一个风口 | 知乎专栏](https://zhuanlan.zhihu.com/p/31181247)<br />
简评： 行人重识别（Person re-identification）也称行人再识别，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术。广泛被认为是一个图像检索的子问题。给定一个监控行人图像，检索跨设备下的该行人图像。旨在弥补目前固定的摄像头的视觉局限，并可与行人检测/行人跟踪技术相结合，可广泛应用于智能视频监控、智能安保等领域。
- [加速云CEO邬钢：FPGA在深度学习中的应用 | 斗鱼](https://v.douyu.com/show/yjwzOvp2mjMZVRm9)<br />
简评：加速云成立于2015年9月，是国内为数不多的具备FPGA硬件加速方案实施才干的厂商。加速云的运用场景可分为前端和后端，前端首要会合在智能硬件领域，如无人机运用，而在后端的运用场景可以拿云计算举例，加速云研发的大数据加速产品已广泛运用于数据基地、云计算、机器视觉、深度学习、高功用计算、科技金融等领域，为腾讯、阿里、科大讯飞、京东等首要客户提供了效力支撑。
- [深度学习中的「卷积层」如何深入理解 | 雷克世界](https://mp.weixin.qq.com/s/wAVbeU2MXWrWXdCCBbR-Wg) [[英文原文]](https://medium.com/@apiltamang/a-gentle-dive-into-the-anatomy-of-a-convolution-layer-6f1024339aca)<br />
简评：在现有深度学习框架下，我们所编写的卷积层往往是一个单行语句，它可以抽象出许多结构细节。不过，有时候后退一步去揭开一些抽象概念也是一个不错的选择。本文试图阐述卷积层的一个特定的解剖特征，而这是在大多数文章和相关讨论中被忽略的问题。 
- [DeepMind 揭秘 WaveNet 提速一千倍、进驻 Google Assistant 背后的故事 | AI科技评论](https://mp.weixin.qq.com/s/DUsH6wPDqSyq9C_xGY-Lng)<br />
简评：WaveNet 仅一年时间就走出实验室，在 Google Assistant 中落地。在庆贺深度学习又一次完全颠覆传统做法的同时，大家想必也会好奇，到底 DeepMind 做了哪些改进才得以实现这样数量级的效率提升呢？DeepMind 自己最近就发布了介绍商业化改进后的 WaveNet 的论文，并撰写了一篇博文通俗地介绍了其中的改进点。 
