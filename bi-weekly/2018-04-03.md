---
layout: default
---

# 嵌入式AI 双周简报 (2018-04-03)

## 业界新闻

- [Facebook 宣布 Caffe2 代码正式并入 PyTorch 意味着什么？ | 知乎](https://www.zhihu.com/question/270578639)<br />
简评：贾扬清：因为PyTorch有优秀的前端，Caffe2有优秀的后端，整合起来以后可以进一步最大化开发者的效率。目前FAIR大概有超过一半的项目在使用PyTorch，而产品线全线在使用Caffe2，所以两边都有很强的动力来整合优势。
- [Google 和 Nvidia 强强联手，带来优化版 TensorFlow 1.7 | 雷锋网](https://www.leiphone.com/news/201803/Rp1aDiZlKDYbx94W.html?viewType=weixin)<br />
简评：谷歌和英伟达宣布将 NVIDIA TensorRT 集成到 TensorFlow 1.7 中。在谷歌开发者博客中，他们介绍了此次合作的详细信息以及整合之后的性能。
- [赛灵思推颠覆性AI芯片 正面宣战英伟达英特尔 | 智东西](http://mp.weixin.qq.com/s/e3-HO5MvHfeH71b7_zIo1Q)<br />
简评：全球FPGA芯片巨头赛灵思推出全新一代AI芯片架构ACAP，并将基于这套架构推出一系列芯片新品；其中首款代号为“珠穆朗玛峰（Everest）”的AI芯片新品将采用台积电7nm工艺打造，今年内实现流片，2019年向客户交付发货。
- [黄仁勋发布全球最大GPU，超算级逆天算力，仅售39.9万美元 | 新智元](http://mp.weixin.qq.com/s/2LtOvG17k_oPaEIigKtRNw)<br />
简评：英伟达CEO黄仁勋说两件大事，一是发布了迄今最大的GPU，二是暂定自动驾驶暂停研发。随后英伟达股价下跌3.8%。GPU正在成为一种计算范式，但本质性突破乏善可陈，教主一路回顾过去创下的纪录，而鼎盛之下，衰退的迹象，似乎已经潜藏。
- [联发科P60解析：AI加持，对标骁龙660 | EETOP](http://mp.weixin.qq.com/s/1ECoPW604koqu-lVBC2lbw)<br />
简评：联发科在北京798艺术中心发布了首款内建多核心人工智能处理器——Helio P60。P60是具有Neuro Pilot AI技术的新一代智能手机SOC，主打人工智能技术，在各家都争相推出AI芯片的今天，联发科也赶上了末班车，今天我们就来看看这颗极有可能成为一代“神U”的联发科P60。
- [AMD，要把嵌入式处理器市场进行到底 | 来自IT的我](http://mp.weixin.qq.com/s/jE40fMgtYArc421k3D5rVg)<br />
简评：嵌入式不仅是智能手机终端的市场。也是因为如此，AMD一度暂缓了数据中心，进军嵌入式处理器的市场。新年伊始，AMD发布了霄龙嵌入式3000系列处理器、锐龙嵌入式V1000系列处理器，两款最新的产品。

## 论文

- [1803.08375] [Deep Learning using Rectified Linear Units (ReLU)](https://arxiv.org/abs/1803.08375)<br />
简评：本文介绍了在深度神经网络中使用整流线性单元(ReLU)作为分类函数的方法。传统上，ReLU作为DNNs中的激活函数，以Softmax函数为分类函数。然而，除了Softmax之外，还有一些关于使用分类功能的研究，这项研究是对这些功能的补充。
- [1803.08225] [PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model](https://arxiv.org/abs/1803.08225)<br />
简评：本文提出了一种利用高效单镜头模型对多人图像进行姿态估计和实例分割的自底向上方法。建议的PersonLab模型使用基于部分的建模来处理语义层次的推理和对象部分关联。
- [1803.09050] [Learning to Reweight Examples for Robust Deep Learning](https://arxiv.org/abs/1803.09050)<br />
简评：深度神经网络已经被证明是非常强大的建模工具，用于许多有监督的学习任务，涉及复杂的输入模式。然而，它们也很容易被训练集偏见和标签噪音所取代。除了不同的正则化器之外，例子重加权算法是解决这些问题的常用方法。
- [1803.08319] [Learning to Detect and Track Visible and Occluded Body Joints in a Virtual World](https://arxiv.org/abs/1803.08319)<br />
简评：我们提出了一个深层的网络架构，它可以联合提取人们的身体部分，并将其与短暂的时间跨度联系起来。我们的模型明确地处理了闭塞的身体部分，通过产生幻觉的不可见关节的解决方案。
- [1803.08251] [Life in the "Matrix": Human Mobility Patterns in the Cyber Space](https://arxiv.org/abs/1803.08251)<br />
简评：在本文中，我们将在网络空间和物理空间的运动中引入一个新的类比。这一类比暗示了一种新的研究人类在线活动的方法，即以一种相似的方式，将网络社区的活动建模为地点之间的运动。

## 开源项目

- [enas: TensorFlow Code for paper "Efficient Neural Architecture Search via Parameter Sharing"](https://github.com/melodyguan/enas)<br />
简评：通过参数共享探索高效的网络结构。
- [caffe-compact](https://github.com/chyh1990/caffe-compact)<br />
简评：Caffe-compact是一个尽可能简化依赖的Caffe版本。
- [TVM+TensorFlow提高神经机器翻译性能 | AI前线](http://mp.weixin.qq.com/s/HquT_mKm7x_rbDGz4Voqpw)<br />
简评：阿里巴巴 PAI-Blade 团队发表于 TVM 的最新博文，文中阐述了如何将 TVM 引入 TensorFlow，使 TensorFlow 中的 batchmul 速度提高 13 倍，同时将端到端神经机器翻译性能提高 1.7 倍。AI 前线对原文进行了编译。
- [Uber开源神经进化算法开发的交互式可视化工具VINE | 机器之心](http://mp.weixin.qq.com/s/7g81BnGAD5DpS_1pDxA6QQ)<br />
简评：Uber 开源了神经进化算法开发的交互式可视化工具 VINE，该工具可以轻松实现神经网络群体的各种特定指标以及适应度分数的可视化和随时间的变化，用户可对其进行实时评估。此外，VINE 还支持默认功能之外的高级选项和自定义可视化。
- [英特尔开源nGraph编译器：从多框架到多设备轻松实现模型部署 | 机器之心](http://mp.weixin.qq.com/s/Xm-D9eVv3eN-QP84cPqLsQ)<br />
简评：英特尔的人工智能产品团队宣布开源 nGraph，这是一个面向各种设备和框架的深度神经网络模型编译器。有了 nGraph，数据科学家能够专注于数据科学研发，不需要担心如何将 DNN 模型部署到各种不同设备做高效训练和运行。

## 博文

- [百度深度学习平台PaddlePaddle框架解析 | 机器之心](http://mp.weixin.qq.com/s/ync8iu8nmpJoI5Sfnj8DqQ)<br />
简评：PaddlePaddle 是 2016 年 8 月底百度开源的深度学习平台，并且在短时间内迅速引发全球开发热度，成为 Github Pull Request 数量增速极高的开源深度学习平台之一。
- [中科院计算所研究员陈云霁：深度学习处理器的现状及发展 | 北大AI公开课笔记](http://mp.weixin.qq.com/s/oFNoM0cjLD0CgcdwWojxhw)<br />
简评：北京大学“人工智能前沿与产业趋势”第五讲，本期中科院计算机所研究员陈云霁授课主题为“深度学习处理器的现状及发展”，分享了深度学习的工作方式、深度学习处理器的发展、寒武纪目前的科研成果等相关内容。
- [如何评价最新的YOLOv3？](https://www.zhihu.com/question/269909535)<br />
简评：YOLOv3的最新评价。
- [探索嵌入式应用框架（EAF）| 喔家ArchiSelf](http://mp.weixin.qq.com/s/Fni3bO0ap7gHyVnzD8RiTA)<br />
简评：EAF是Embedded Application Framework 的缩写，即嵌入式应用框架。嵌入式应用框架是 Application framework的一种， 是在嵌入式领域的应用框架。
- [增加深度，加速神经网络优化？这是一份反直觉的实验结果 | 机器之心](http://mp.weixin.qq.com/s/PC5KXU0zmE1eg2k_S9_pQg)<br />
简评：深度学习的根本理论问题之一是「深度有何作用」？虽然增加神经网络的层数可以提高其性能，但是训练和优化的难度也随之增加。本文却给出了一个相反观点，有时增加深度反而可以加速网络优化；同时提出端到端更新规则，证明深度网络过度的参数化（overparameterization）也可能是件好事。
- [级联MobileNet-V2实现人脸关键点检测（附训练源码）| 机器之心](https://mp.weixin.qq.com/s/ZrnAqDJCLtMy_qTQ2RZT0A)<br />
简评：为了能在移动端进行实时的人脸关键点检测，本实验采用最新的轻量化模型——MobileNet-V2 作为基础模型，在 CelebA 数据上，进行两级的级联 MobileNet-V2 实现人脸关键点检测。首先，将 CelebA 数据作为第一级 MobileNet-V2 的输入，经第一级 MobileNet-V2 得到粗略的关键点位置；然后，依据第一级 MobileNet-V2 的输出，采取一定的裁剪策略，将人脸区域从原始数据上裁剪出来作为第二级 MobileNet-V2 的输入；最后，经第二级 MobileNet-V2 输出最终人脸关键点定位信息。经初步训练，最终网络单模型不到 1M，仅 956KB，单张图片 inference 耗时 6ms（采用 GTX1080 在未优化的 Caffe）。实验结果表明，MobileNet-V2 是一个性能极佳的轻量化模型，可以采用较少的参数获得较好的性能；同时，级联的操作可达到从粗到精的关键点定位。




----

Editor: 王建章、袁帅、张先轶

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" 
